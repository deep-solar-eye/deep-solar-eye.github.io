<!DOCTYPE html>
<html lang="en-us">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1" />
  
  <title>DeepSolarEye: A Deep Learning Based Solar Panel Visual Analytics</title>
  <meta property="og:title" content="DeepSolarEye: A Deep Learning Based Solar Panel Visual Analytics" />
  <meta name="twitter:title" content="DeepSolarEye: A Deep Learning Based Solar Panel Visual Analytics" />
  

  
  <meta name="description" content="Computer vision on solar panels">
  <meta property="og:description" content="Computer vision on solar panels">
  <meta name="twitter:description" content="Computer vision on solar panels">
  

  <meta name="author" content=""/>
  <meta property="og:site_name" content="Deep Solar Eye" />
  <meta property="og:url" content="/posts/blog/" />

  
  <meta name="twitter:card" content="summary" />

  

  
  <meta property="og:type" content="article" />
  
  
  
  <meta name="generator" content="Hugo 0.37" /><link href="https://fonts.googleapis.com/css?family=Open+Sans:300,400,600" rel="stylesheet">
  <link rel="stylesheet" href="/css/style.css" />
  <script type="text/javascript" src="/js/bundle.js"></script>
  

</head>

<body>
  <header class="l-header">
    
    <h1 class="c-title p-title"><a href="/" class="p-title__link">Deep Solar Eye</a></h1>
    <p class="p-subtitle">
      Deep Learning-based Solar Panel Visual Analytics
    </p>
    
  </header>
  <main id="main" class="l-main">


<article class="p-article">
  <header>
    <h2 class="c-title c-article__title" style="font-weight: bold; color: black">Method</h2>
  </header>
  
  <div class="c-article__summary">
<p align="justify">The impact of soiling on solar panels is an important and well-studied problem in renewable energy sector. In this project, we present the first convolutional neural network (CNN) based approach for solar panel soiling and defect analysis. Our approach takes an RGB image of solar panel and environmental factors as inputs to predict power loss, soiling localization, and soiling type. In computer vision, localization is a complex task which typically requires manually labeled training data such as bounding boxes or segmentation masks. Our proposed approach consists of specialized four stages which completely avoids localization ground truth and only needs panel images with power loss labels for training.</p>
  
 <p align="justify">The region of impact area obtained from the predicted localization masks are classified into soiling types using the webly supervised learning. For improving localization capabilities of CNNs, we introduce a novel bi-directional input-aware fusion (BiDIAF) block that reinforces the input at different levels of CNN to learn input-specific feature maps. Our empirical study shows that BiDIAF improves the power loss prediction accuracy by about 3% and localization accuracy by about 4%. Our end-to-end model yields further improvement of about 24% on localization when learned in a weakly supervised manner. Our approach is generalizable and showed promising results on web crawled solar panel images. Our system has a frame rate of 22 fps (including all steps) on a NVIDIA TitanX GPU. Additionally, we collected first of itâ€™s kind dataset for solar panel image analysis consisting 45,000+ images.</p>
    <br>
  <p align="justify">More details in <a href="https://arxiv.org/abs/1710.03811" target="_blank">paper</a> published at WACV 2018.</p>
  <br>
<img src="/img/panelImage_PV.png" alt="Panel setup" />
<p align="center"><b>Figure:</b> Qualitative results generated by DeepSolarEye</p>
<br>

  </div>
</article>
  </main>
  


<br><br><br><br>
    <br><br><br><br>
  

</body>
</html>

