<!DOCTYPE html>
<html lang="en-us">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1" />
  
  <title>Deep Solar Eye</title>
  <meta property="og:title" content="Deep Solar Eye" />
  <meta name="twitter:title" content="Deep Solar Eye" />
  

  
  <meta name="description" content="Computer vision on solar panels">
  <meta property="og:description" content="Computer vision on solar panels">
  <meta name="twitter:description" content="Computer vision on solar panels">
  

  <meta name="author" content=""/>
  <meta property="og:site_name" content="Deep Solar Eye" />
  <meta property="og:url" content="/" />

  
  <meta name="twitter:card" content="summary" />

  

  
  <meta property="og:type" content="website" />
  
  
  <meta name="generator" content="Hugo 0.37" /><link href="https://fonts.googleapis.com/css?family=Open+Sans:300,400,600" rel="stylesheet">
  <link rel="stylesheet" href="/css/style.css" />
  <link href="/index.xml" rel="alternate" type="application/rss+xml" title="Deep Solar Eye" />
  
  <script type="text/javascript" src="/js/bundle.js"></script>
  

</head>

<body>
  <header class="l-header">
    
    <h1 class="c-title p-title"><a href="/" class="p-title__link">Deep Solar Eye</a></h1>
    <p class="p-subtitle">
      Deep Learning-based Solar Panel Visual Analytics
    </p>
    
  </header>
  <main id="main" class="l-main">

<article class="c-article p-list-article">
  <div class="c-article__summary">
    <p align="justify">The impact of soiling on solar panels is an important and well-studied problem in renewable energy sector. In this project, we present the first convolutional neural network (CNN) based approach for solar panel soiling and defect analysis. Our approach takes an RGB image of solar panel and environmental factors as inputs to predict power loss, soiling localization, and soiling type. In computer vision, localization is a complex task which typically requires manually labeled training data such as bounding boxes or segmentation masks. Our proposed approach consists of specialized four stages which completely avoids localization ground truth and only needs panel images with power loss labels for training.</p>
  </div>
  <a href="/posts/blog/" class="c-article__btn p-list-article__btn">Read more</a>
</article>

<article class="c-article p-list-article">
  <header>
    <h2 class="c-title c-article__title" style="font-weight: bold; color: black">PV-Net Dataset</h2>
  </header>
  <div class="c-article__summary">
    <p align="justify">We create a first-of-its-kind dataset, <b>PV-Net</b>, comprising of <b>45,754 images</b> of solar panels with power loss labels. Our experimental setup consists of two identical solar panels, which are kept side by side with an RGB camera facing them.</p>
<br>
<img src="/img/powerDiag.png" alt="Data acquisition setup" width="85%" align="middle"/>
<br>
<p align="justify"> Soiling experiments were conducted on the first panel (close to the camera) while the other panel was used for reference. Images were captured at every 5 seconds and power generated by the panels was recorded. Soiling impact is reported as the percentage power loss with respect to the reference panel. Our data recording methodology was aimed to capture various types of soiling and their impact on PV panel. For this, we exposed the panel to different types of soiling in terms of color (red, brown, and gray), particle size (sand, dust, and talcum powder), and thickness under natural environmental conditions. Some of the thick patches correspond to high power losses as much as 90%. The data set was collected for about a month and was enriched with large variations in soiling due to both experimental (e.g. dust with varying thickness, blob sizes, and patches) and natural means (e.g. wind and precipitation). Besides power loss corresponding to the soiled panel, our data set also contains information about environmental factors (solar irradiance and timestamps).</p>

<br>

<p align="justify">The PV-Net dataset can be <a href="https://drive.google.com/open?id=1qB5dPWZMi2-12sLHDykHb9i6GibbJ46l" target="_blank">downloaded here</a>. It is released under the <a href="https://creativecommons.org/licenses/by-nc-sa/2.0/">Creative Commons license</a> and <a href="https://en.wikipedia.org/wiki/Wikipedia:Copyrights#Reusers.27_rights_and_obligations">copyright</a> terms.</p>

<br>

<p align="justify">If you are using this dataset, please cite the following paper:</p>
    <br>
  <p align="justify"> <i>S. Mehta, A. P. Azad, S. A. Chemmengath, V. Raykar and S. Kalyanaraman, <a href="https://arxiv.org/abs/1710.03811" target="_blank">DeepSolarEye: Power Loss Prediction and Weakly Supervised Soiling Localization via Fully Convolutional Networks for Solar Panels</a>," 2018 IEEE Winter Conference on Applications of Computer Vision (WACV), Lake Tahoe, NV, 2018, pp. 333-342.</i>
  </p>
  </div>
  
</article>
    
  <br>
    <br>
    <br>
    <br>
    <br>
    
  </main>

  

</body>
</html>

